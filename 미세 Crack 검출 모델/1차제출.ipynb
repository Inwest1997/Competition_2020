{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Activation, Average\n",
    "from keras.utils import to_categorical\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import cifar10\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.utils.np_utils import to_categorical \n",
    "from keras import Sequential\n",
    "from keras.layers import Conv2D, Flatten, Dense,Dropout,MaxPool2D, Activation,BatchNormalization\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from keras.layers import Dense, Input, Activation\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 디렉터리 내 파일 리스트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path_dir = \"/home/workspace/data/.train/.task153/data/train/\"\n",
    "file_list = os.listdir(path_dir)\n",
    "# print(file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CSV 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = np.loadtxt(\"/home/workspace/data/.train/.task153/data/train/train.csv\",delimiter=\",\",dtype='str')\n",
    "train_df = pd.DataFrame(csv_data[1:], columns=['file_name', 'tile_name', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 이미지 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as pilimg\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "path_dir = '/home/workspace/data/.train/.task153/data/train/'\n",
    "\n",
    "pix=[]\n",
    "for i in range(len(train_df)) :\n",
    "    im = pilimg.open( path_dir + train_df['file_name'][i] )\n",
    "    im = np.array(im)\n",
    "    pix.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= np.array(train_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=360,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.8, # 0.9\n",
    "        # brightness_range=[0.01, 0.1], # 밝기는 0.01~0.1로 테스트 해보기\n",
    "        # horizontal_flip=True,\n",
    "        # vertical_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 백업용\n",
    "# datagen = ImageDataGenerator(\n",
    "#         rotation_range=40,\n",
    "#         width_shift_range=0.2,\n",
    "#         height_shift_range=0.2,\n",
    "#         shear_range=0.2,\n",
    "#         zoom_range=0.2,\n",
    "#         horizontal_flip=True,\n",
    "#         fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 정상데이터 증폭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnt = 0\n",
    "\n",
    "# for i in range(len(train_df)):\n",
    "    \n",
    "#     if(train_df['label'][i]=='0'): # 정상데이터\n",
    "#         im = pilimg.open( path_dir + train_df['file_name'][i] )\n",
    "                \n",
    "#         x = img_to_array(im)  # (3, 150, 150) 크기의 NumPy 배열\n",
    "#         x = x.reshape((1,) + x.shape)  # (1, 3, 150, 150) 크기의 NumPy 배열\n",
    "    \n",
    "#         i = 0\n",
    "#         for batch in datagen.flow(x, batch_size=1):\n",
    "            \n",
    "#             batch = np.squeeze(batch) # 차원 축소\n",
    "            \n",
    "#             if i != 0:\n",
    "#                 batch = np.array(batch)\n",
    "#                 pix.append(batch)\n",
    "#                 cnt += 1\n",
    "            \n",
    "#             i += 1\n",
    "#             if i > 1: # 2배로 증가시키기\n",
    "#                 break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(cnt):\n",
    "#     y = np.append(y, '0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 크랙데이터 증폭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_df)):\n",
    "    \n",
    "    if(train_df['label'][i]=='1'): # 크랙데이터\n",
    "        im = pilimg.open( path_dir + train_df['file_name'][i] )\n",
    "                \n",
    "        x = img_to_array(im)  # (3, 150, 150) 크기의 NumPy 배열\n",
    "        x = x.reshape((1,) + x.shape)  # (1, 3, 150, 150) 크기의 NumPy 배열\n",
    "    \n",
    "        i = 0\n",
    "        for batch in datagen.flow(x, batch_size=1):\n",
    "            \n",
    "            batch = np.squeeze(batch) # 차원 축소\n",
    "            \n",
    "            if i != 0:\n",
    "                batch = np.array(batch)\n",
    "                pix.append(batch)\n",
    "            \n",
    "            i += 1\n",
    "            if i > 8: # 8배로 증가시키기\n",
    "            # if i > 17: # 17배로 증가시키기                \n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(y)<len(pix):\n",
    "    y = np.append(y, '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "crack_df= train_df[train_df['label']=='1']\n",
    "count=0\n",
    "fig = plt.figure(figsize=(50,50))\n",
    "rows = 10\n",
    "cols = 5\n",
    "for crack in crack_df['file_name']:\n",
    "    if count==0:\n",
    "        count+=1\n",
    "        continue\n",
    "        \n",
    "    elif count==31:\n",
    "        break\n",
    "    else:\n",
    "        img = pilimg.open( path_dir + crack )\n",
    "        ax = fig.add_subplot(rows, cols, count)\n",
    "        ax.imshow(img)\n",
    "        ax.set_xticks([]), ax.set_yticks([])\n",
    "        count+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 라벨 분포 여부 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "g = sns.countplot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix=np.array(pix)\n",
    "\n",
    "# pix = pix/255.0 # 정규화 하면 점수가 떨어짐...\n",
    "\n",
    "pix=pix.astype('int32')\n",
    "y=y.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pix.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(26025, 68, 68, 3)\n",
    "(26025,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 훈련용 데이터, 검증 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(pix, y, test_size = 0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = shape=(68, 68, 3)\n",
    "model_input = Input(shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=50\n",
    "EPOCH=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With data augmentation to prevent overfitting (accuracy 0.99286)\n",
    "\n",
    "# datagen = ImageDataGenerator(\n",
    "#         rescale = 1./255,\n",
    "#         featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "#         samplewise_center=False,  # set each sample mean to 0\n",
    "#         featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "#         samplewise_std_normalization=False,  # divide each input by its std\n",
    "#         zca_whitening=False,  # apply ZCA whitening\n",
    "#         rotation_range=30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "#         zoom_range = 0, # Randomly zoom image \n",
    "#         width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "#         height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "#         horizontal_flip=True,  # randomly flip images\n",
    "#         vertical_flip=True)  # randomly flip images\n",
    "\n",
    "\n",
    "# datagen.fit(pix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_f1score', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### verbose=1, patience 수치 테스트 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=2, patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_train(model, num_epochs): \n",
    "    \n",
    "    \n",
    "    filepath = '/home/workspace/user-workspace/workspace/weights/' + model.name #+ '.hdf5'\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_f1score', \n",
    "                                 save_weights_only=True, \n",
    "                                 save_best_only=True,\n",
    "                                 mode='max')#, period=1)\n",
    "    \n",
    "#     tensor_board = TensorBoard(log_dir='logs/', histogram_freq=0, batch_size=32)                              \n",
    "    history = model.fit(x=X_train, y=Y_train, batch_size=BATCH_SIZE, epochs=num_epochs, verbose=2, callbacks=[checkpoint,learning_rate_reduction,early_stopping], validation_split=0.2)\n",
    "    # history = model.fit(x=pix, y=y, batch_size=BATCH_SIZE, epochs=num_epochs, verbose=2, callbacks=[checkpoint,learning_rate_reduction,early_stopping], validation_split=0.2)\n",
    "    # Fit the model\n",
    "#     history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=BATCH_SIZE),\n",
    "#                               epochs = num_epochs, \n",
    "#                               validation_data = (X_val,Y_val),\n",
    "#                               verbose = 2,\n",
    "#                              #steps_per_epoch=X_train.shape[0] // BATCH_SIZE,\n",
    "#                               callbacks=[checkpoint,learning_rate_reduction])\n",
    "# #                               validation_split=0.2)\n",
    "                                \n",
    "    fig, ax = plt.subplots(3,1)\n",
    "    ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "    ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "    legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "    ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "    ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "    legend = ax[1].legend(loc='best', shadow=True)\n",
    "    \n",
    "    ax[2].plot(history.history['f1score'], color='b', label=\"Training accuracy\")\n",
    "    ax[2].plot(history.history['val_f1score'], color='r',label=\"Validation accuracy\")\n",
    "    legend = ax[2].legend(loc='best', shadow=True)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def evaluate_error(model):\n",
    "#     pred = model.predict(X_val, batch_size = 25)\n",
    "#     pred = np.argmax(pred, axis=1)\n",
    "#     pred = np.expand_dims(pred, axis=1) # make same shape as y_test\n",
    "#     error = np.sum(np.not_equal(pred, Y_val)) / Y_val.shape[0]    \n",
    "#     return error\n",
    "\n",
    "\n",
    "#     pred = model.predict(X_val)#, batch_size = batch_size)\n",
    "#     Y_pred_classes = np.argmax(pred,axis = 1) \n",
    "#     report = classification_report(Y_val, Y_pred_classes)\n",
    "#     print(report)\n",
    "\n",
    "#     score = model.evaluate(X_val, Y_val, batch_size=BATCH_SIZE,\n",
    "#                                             verbose=2 )\n",
    "#     print(score)\n",
    "    _loss, _acc, _precision, _recall, _f1score = model.evaluate(X_val, Y_val, batch_size=BATCH_SIZE, verbose=1)\n",
    "    print('loss: {:.10f}, accuracy: {:.10f},\\n precision: {:.10f}, recall: {:.10f},\\n f1score: {:.10f}\\n\\n'.format(_loss, _acc, _precision, _recall, _f1score))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dropout을 한번 더 넣어야 할지 ????? => 층마다 넣어야 하는지\n",
    "##### BATCH, DROPOUT 어느 거 하나만 쓰는게 좋은지????? => 동시에 쓰는게 좋은지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def recall(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Negative) = 실제 값이 1(Positive) 전체\n",
    "    count_true_positive_false_negative = K.sum(y_target_yn)\n",
    "\n",
    "    # Recall =  (True Positive) / (True Positive + False Negative)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Positive) = 예측 값이 1(Positive) 전체\n",
    "    count_true_positive_false_positive = K.sum(y_pred_yn)\n",
    "\n",
    "    # Precision = (True Positive) / (True Positive + False Positive)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1score(y_target, y_pred):\n",
    "    _recall = recall(y_target, y_pred)\n",
    "    _precision = precision(y_target, y_pred)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    _f1score = ( 2 * _recall * _precision) / (_recall + _precision+ K.epsilon())\n",
    "    \n",
    "    # return a single tensor value\n",
    "    return _f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first Model\n",
    "def VGG_model(model_input):\n",
    "    model = tf.keras.applications.VGG16(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_tensor=model_input,\n",
    "        input_shape=(68, 68, 3),\n",
    "        pooling='max'\n",
    "        # classes=1\n",
    "    )\n",
    "\n",
    "    x = model.output\n",
    "\n",
    "    # x = Dense(256, name='fully_VGG', kernel_initializer='glorot_uniform', kernel_regularizer=keras.regularizers.l2(0.01), bias_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)    \n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Dense(1, activation='sigmoid', name='sigmoid_VGG')(x)\n",
    "    \n",
    "    model = Model(model_input, x, name = 'VGG_model')\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(), metrics=['accuracy', precision, recall, f1score])  \n",
    "    return model\n",
    "\n",
    "vgg_model = VGG_model(model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # first Model # 백업용#####################3\n",
    "# def VGG_model(model_input):\n",
    "    \n",
    "#     model = tf.keras.applications.VGG16(\n",
    "#         include_top=False, # True, False\n",
    "#         weights=\"imagenet\", # imagenet, None\n",
    "#         input_tensor=model_input,\n",
    "#         input_shape=(68, 68, 3),\n",
    "#         pooling='max'\n",
    "#         # classes=1\n",
    "#     )\n",
    "\n",
    "#     x = model.output\n",
    "    \n",
    "#     x = Dropout(0.5)(x)\n",
    "    \n",
    "#     # x = Dense(1024, name='fully_VGG', kernel_initializer='glorot_uniform', kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
    "#     # x = BatchNormalization()(x)\n",
    "#     # x = Dropout(0.05)(x)\n",
    "#     # x = Activation('relu')(x)\n",
    "    \n",
    "#     # x = Dense(512, kernel_initializer='glorot_uniform', kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
    "#     # x = BatchNormalization()(x)\n",
    "#     # x = Dropout(0.05)(x)\n",
    "#     # x = Activation('relu')(x)\n",
    "#     # BatchNormalization, Activation 위치를 바꿔야 하는건가...\n",
    "    \n",
    "#     # x = Dense(256, activation='relu', kernel_initializer='glorot_uniform', kernel_regularizer=keras.regularizers.l2(0.1))(x)\n",
    "#     # x = BatchNormalization()(x)\n",
    "#     # x = Dropout(0.5)(x)\n",
    "#     # x = Activation('relu')(x)    \n",
    "    \n",
    "#     x = Dense(1, activation='sigmoid', name='sigmoid_VGG')(x)\n",
    "    \n",
    "#     model = Model(model_input, x, name = 'VGG_model')\n",
    "#     model.compile(loss=\"binary_crossentropy\", optimizer=Adam(), metrics=['accuracy', precision, recall, f1score])  \n",
    "#     return model\n",
    "\n",
    "\n",
    "# vgg_model = VGG_model(model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 테스트중 ##########################\n",
    "# ##  second Model\n",
    "# def NASNet_model(model_input):\n",
    "    \n",
    "#     model =tf.keras.applications.NASNetLarge (\n",
    "#         input_shape=(68, 68, 3),\n",
    "#         include_top=True,\n",
    "#         weights=None, # imagenet\n",
    "#         input_tensor=model_input,\n",
    "#         pooling='max'\n",
    "#         # classes=1,\n",
    "#     )\n",
    "\n",
    "#     x = model.output\n",
    "#     x = Dense(500, activation='relu' name='fully_NASNet', kernel_initializer='glorot_uniform', kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     # x = Dropout(0.1)(x)  \n",
    "#     # x = Activation('relu')(x)\n",
    "\n",
    "#     x = Dense(1, activation='sigmoid', name='sigmoid_NASNet')(x)\n",
    "#     model = Model(model_input, x, name='NASNet_model')\n",
    "#     # model.summary()\n",
    "#     model.compile(loss=\"binary_crossentropy\", optimizer=Adam(), metrics=['accuracy', precision, recall, f1score])   \n",
    "\n",
    "#     return model\n",
    "\n",
    "# nasnet_model = NASNet_model(model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 테스트중 ##########################\n",
    "# ##  second Model\n",
    "# def NASNet_model(model_input):\n",
    "    \n",
    "#     model =tf.keras.applications.NASNetMobile (\n",
    "#                                             input_shape=(68, 68, 3),\n",
    "#                                             include_top=True,\n",
    "#                                             weights=None,\n",
    "#                                             input_tensor=model_input,\n",
    "#                                             pooling='max',\n",
    "#                                             classes=1,\n",
    "#                                             )\n",
    "\n",
    "#     x = model.output\n",
    "#     x = Dense(1024, name='fully_NASNet', kernel_initializer='glorot_uniform', kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
    "    \n",
    "#     # x = BatchNormalization()(x)\n",
    "#     x = Dropout(0.1)(x)\n",
    "    \n",
    "#     x = Activation('relu')(x)\n",
    "#     x = Dense(512, kernel_initializer='glorot_uniform', kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
    "    \n",
    "#     # x = BatchNormalization()(x)\n",
    "#     x = Dropout(0.1)(x)\n",
    "    \n",
    "#     x = Activation('relu')(x)\n",
    "#     x = Dense(1, activation='sigmoid', name='sigmoid_NASNet')(x)\n",
    "#     model = Model(model_input, x, name='NASNet_model')\n",
    "#     model.compile(loss=\"binary_crossentropy\", optimizer=Adam(), metrics=['accuracy', precision, recall, f1score])   \n",
    "\n",
    "#     return model\n",
    "\n",
    "# nasnet_model = NASNet_model(model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 테스트중 ##########################\n",
    "# ##  second Model\n",
    "# def InResNet_model(model_input):\n",
    "    \n",
    "#     model =tf.keras.applications.InceptionResNetV2 (\n",
    "#                                             input_shape=(75, 75, 3),\n",
    "#                                             include_top=False,\n",
    "#                                             weights=\"imagenet\",\n",
    "#                                             input_tensor=model_input,\n",
    "#                                             pooling='max',\n",
    "#                                             classes=1,\n",
    "#                                             classifier_activation=\"sigmoid\"\n",
    "#                                             )\n",
    "    \n",
    "#     x = model.output\n",
    "#     x = Dense(1024, name='fully_InResNet', kernel_initializer='glorot_uniform', kernel_regularizer=keras.regularizers.l2(0.001), data_format = 'channels_first')(x)\n",
    "    \n",
    "#     # x = BatchNormalization()(x)\n",
    "#     x = Dropout(0.1)(x)\n",
    "    \n",
    "#     x = Activation('relu')(x)\n",
    "#     x = Dense(512, kernel_initializer='glorot_uniform', kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
    "    \n",
    "#     # x = BatchNormalization()(x)\n",
    "#     x = Dropout(0.1)(x)\n",
    "    \n",
    "#     x = Activation('relu')(x)\n",
    "#     x = Dense(1, activation='sigmoid', name='sigmoid_InResNet')(x)\n",
    "#     model = Model(model_input, x, name='InResNet_model')\n",
    "#     model.compile(loss=\"binary_crossentropy\", optimizer=Adam(), metrics=['accuracy', precision, recall, f1score])   \n",
    "\n",
    "#     return model\n",
    "\n",
    "# inresnet_model = InResNet_model(model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # third Model\n",
    "def DenseNet201_model(model_input):\n",
    "    model = tf.keras.applications.DenseNet201(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_tensor=model_input,\n",
    "        input_shape=(68, 68, 3),\n",
    "        pooling='max'\n",
    "        # classes=1\n",
    "    )\n",
    "\n",
    "    x = model.output\n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = Dense(960, name='fully_DenseNet201', kernel_initializer='glorot_uniform', kernel_regularizer=keras.regularizers.l2(0.01), bias_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = Dense(480, kernel_initializer='glorot_uniform', kernel_regularizer=keras.regularizers.l2(0.01), bias_regularizer=l2(0.01))(x)    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)    \n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "#     x = Dense(240, kernel_initializer='glorot_uniform', kernel_regularizer=keras.regularizers.l2(0.1), bias_regularizer=l2(0.1))(x)    \n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Activation('relu')(x)    \n",
    "#     x = Dropout(0.8)(x)\n",
    "\n",
    "    x = Dense(1, activation='sigmoid', name='sigmoid_DenseNet201')(x)\n",
    "    \n",
    "    model = Model(model_input, x, name = 'DenseNet201_model')\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(), metrics=['accuracy', precision, recall, f1score])  \n",
    "    return model\n",
    "\n",
    "denseNet201_model = DenseNet201_model(model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # third Model # 백업용 ###############################\n",
    "# def DenseNet201_model(model_input):\n",
    "#     model = tf.keras.applications.DenseNet201(\n",
    "#         include_top=False,\n",
    "#         weights=\"imagenet\",\n",
    "#         input_tensor=model_input,\n",
    "#         input_shape=(68, 68, 3),\n",
    "#         pooling='max'\n",
    "#         # classes=1\n",
    "#     )\n",
    "#     x = model.output\n",
    "#     # x = Dropout(0.5)(x)\n",
    "    \n",
    "#     x = Dense(960, name='fully_DenseNet201', activation='relu', kernel_initializer='glorot_uniform', kernel_regularizer=keras.regularizers.l2(0.1))(x)\n",
    "#     # x = BatchNormalization()(x)\n",
    "#     x = Dropout(0.5)(x)\n",
    "#     # x = Activation('relu')(x)\n",
    "#     # Activation을 Dense 안으로...\n",
    "    \n",
    "#     x = Dense(480, activation='relu', kernel_initializer='glorot_uniform', kernel_regularizer=keras.regularizers.l2(0.1))(x)\n",
    "#     # x = BatchNormalization()(x)\n",
    "#     x = Dropout(0.5)(x)\n",
    "#     # x = Activation('relu')(x)    \n",
    "    \n",
    "#     # x = Dense(240, activation='relu', kernel_initializer='glorot_uniform', kernel_regularizer=keras.regularizers.l2(0.1))(x)\n",
    "#     # x = BatchNormalization()(x)\n",
    "#     # x = Dropout(0.5)(x)\n",
    "#     # x = Activation('relu')(x)    \n",
    "    \n",
    "#     x = Dense(1, activation='sigmoid', name='sigmoid_DenseNet201')(x)\n",
    "    \n",
    "#     model = Model(model_input, x, name = 'DenseNet201_model')\n",
    "#     model.compile(loss=\"binary_crossentropy\", optimizer=Adam(), metrics=['accuracy', precision, recall, f1score])  \n",
    "    \n",
    "#     return model\n",
    "\n",
    "# denseNet201_model = DenseNet201_model(model_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 가중치 초기화 방법\n",
    "# glorot_uniform // 쉐이비어\n",
    "# random_uniform // 기존"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### L2규제\n",
    "# kernel_regularizer=keras.regularizers.l2(0.001)\n",
    "# kernel_regularizer=regularizers.l2(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history= compile_and_train(vgg_model, num_epochs=EPOCH)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Epoch 1/100\n",
    "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0209s vs `on_train_batch_end` time: 0.0331s). Check your callbacks.\n",
    "334/334 - 52s - loss: 0.7314 - accuracy: 0.6184 - precision: 0.5965 - recall: 0.8215 - f1score: 0.6836 - val_loss: 2.3890 - val_accuracy: 0.5127 - val_precision: 0.5126 - val_recall: 1.0000 - val_f1score: 0.6750\n",
    "Epoch 2/100\n",
    "334/334 - 19s - loss: 0.6197 - accuracy: 0.6912 - precision: 0.6556 - recall: 0.8756 - f1score: 0.7433 - val_loss: 1.4149 - val_accuracy: 0.5127 - val_precision: 0.5126 - val_recall: 1.0000 - val_f1score: 0.6750\n",
    "Epoch 3/100\n",
    "334/334 - 19s - loss: 0.6013 - accuracy: 0.7020 - precision: 0.6742 - recall: 0.8448 - f1score: 0.7427 - val_loss: 158302.3125 - val_accuracy: 0.5010 - val_precision: 0.5478 - val_recall: 0.0665 - val_f1score: 0.1166\n",
    "Epoch 4/100\n",
    "334/334 - 19s - loss: 0.5187 - accuracy: 0.7657 - precision: 0.7237 - recall: 0.9061 - f1score: 0.7982 - val_loss: 0.7353 - val_accuracy: 0.5125 - val_precision: 0.5125 - val_recall: 0.9995 - val_f1score: 0.6748\n",
    "Epoch 5/100\n",
    "334/334 - 20s - loss: 0.3582 - accuracy: 0.8512 - precision: 0.8000 - recall: 0.9530 - f1score: 0.8667 - val_loss: 0.5907 - val_accuracy: 0.6001 - val_precision: 0.5622 - val_recall: 0.9996 - val_f1score: 0.7166\n",
    "Epoch 6/100\n",
    "\n",
    "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
    "334/334 - 20s - loss: 0.2683 - accuracy: 0.8902 - precision: 0.8473 - recall: 0.9633 - f1score: 0.8990 - val_loss: 0.3005 - val_accuracy: 0.8684 - val_precision: 0.7998 - val_recall: 0.9898 - val_f1score: 0.8830\n",
    "Epoch 7/100\n",
    "334/334 - 19s - loss: 0.1983 - accuracy: 0.9268 - precision: 0.8933 - recall: 0.9751 - f1score: 0.9307 - val_loss: 0.3090 - val_accuracy: 0.8461 - val_precision: 0.7723 - val_recall: 0.9951 - val_f1score: 0.8673\n",
    "Epoch 8/100\n",
    "334/334 - 20s - loss: 0.1854 - accuracy: 0.9321 - precision: 0.8968 - recall: 0.9752 - f1score: 0.9327 - val_loss: 0.1525 - val_accuracy: 0.9431 - val_precision: 0.9143 - val_recall: 0.9813 - val_f1score: 0.9457\n",
    "Epoch 9/100\n",
    "\n",
    "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
    "334/334 - 19s - loss: 0.1565 - accuracy: 0.9419 - precision: 0.9146 - recall: 0.9790 - f1score: 0.9443 - val_loss: 0.2229 - val_accuracy: 0.9092 - val_precision: 0.8527 - val_recall: 0.9940 - val_f1score: 0.9165\n",
    "Epoch 10/100\n",
    "334/334 - 20s - loss: 0.1217 - accuracy: 0.9546 - precision: 0.9338 - recall: 0.9822 - f1score: 0.9564 - val_loss: 0.1361 - val_accuracy: 0.9561 - val_precision: 0.9282 - val_recall: 0.9900 - val_f1score: 0.9573\n",
    "Epoch 11/100\n",
    "334/334 - 20s - loss: 0.1086 - accuracy: 0.9592 - precision: 0.9406 - recall: 0.9821 - f1score: 0.9600 - val_loss: 0.1077 - val_accuracy: 0.9623 - val_precision: 0.9492 - val_recall: 0.9784 - val_f1score: 0.9629\n",
    "Epoch 12/100\n",
    "\n",
    "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
    "334/334 - 20s - loss: 0.1003 - accuracy: 0.9619 - precision: 0.9453 - recall: 0.9833 - f1score: 0.9630 - val_loss: 0.1164 - val_accuracy: 0.9637 - val_precision: 0.9608 - val_recall: 0.9701 - val_f1score: 0.9647\n",
    "Epoch 13/100\n",
    "334/334 - 19s - loss: 0.0844 - accuracy: 0.9675 - precision: 0.9517 - recall: 0.9872 - f1score: 0.9685 - val_loss: 0.2199 - val_accuracy: 0.9635 - val_precision: 0.9744 - val_recall: 0.9544 - val_f1score: 0.9635\n",
    "Epoch 14/100\n",
    "334/334 - 20s - loss: 0.0752 - accuracy: 0.9730 - precision: 0.9615 - recall: 0.9865 - f1score: 0.9733 - val_loss: 0.1873 - val_accuracy: 0.9673 - val_precision: 0.9512 - val_recall: 0.9875 - val_f1score: 0.9684\n",
    "Epoch 15/100\n",
    "\n",
    "Epoch 00015: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
    "334/334 - 20s - loss: 0.0740 - accuracy: 0.9718 - precision: 0.9578 - recall: 0.9888 - f1score: 0.9725 - val_loss: 0.1105 - val_accuracy: 0.9695 - val_precision: 0.9761 - val_recall: 0.9655 - val_f1score: 0.9701\n",
    "Epoch 16/100\n",
    "334/334 - 19s - loss: 0.0652 - accuracy: 0.9744 - precision: 0.9608 - recall: 0.9889 - f1score: 0.9740 - val_loss: 0.1330 - val_accuracy: 0.9688 - val_precision: 0.9790 - val_recall: 0.9604 - val_f1score: 0.9689\n",
    "Epoch 17/100\n",
    "334/334 - 20s - loss: 0.0604 - accuracy: 0.9753 - precision: 0.9644 - recall: 0.9881 - f1score: 0.9756 - val_loss: 0.3101 - val_accuracy: 0.9702 - val_precision: 0.9590 - val_recall: 0.9843 - val_f1score: 0.9709\n",
    "Epoch 18/100\n",
    "\n",
    "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
    "334/334 - 20s - loss: 0.0601 - accuracy: 0.9765 - precision: 0.9666 - recall: 0.9891 - f1score: 0.9772 - val_loss: 1.9983 - val_accuracy: 0.9721 - val_precision: 0.9731 - val_recall: 0.9741 - val_f1score: 0.9730\n",
    "Epoch 19/100\n",
    "334/334 - 19s - loss: 0.0553 - accuracy: 0.9774 - precision: 0.9674 - recall: 0.9895 - f1score: 0.9778 - val_loss: 14.9199 - val_accuracy: 0.9709 - val_precision: 0.9678 - val_recall: 0.9771 - val_f1score: 0.9719\n",
    "Epoch 20/100\n",
    "334/334 - 20s - loss: 0.0547 - accuracy: 0.9768 - precision: 0.9664 - recall: 0.9892 - f1score: 0.9771 - val_loss: 50.8009 - val_accuracy: 0.9736 - val_precision: 0.9750 - val_recall: 0.9752 - val_f1score: 0.9745\n",
    "Epoch 21/100\n",
    "\n",
    "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
    "334/334 - 19s - loss: 0.0518 - accuracy: 0.9791 - precision: 0.9703 - recall: 0.9897 - f1score: 0.9794 - val_loss: 61.9216 - val_accuracy: 0.9712 - val_precision: 0.9633 - val_recall: 0.9824 - val_f1score: 0.9722\n",
    "Epoch 22/100\n",
    "334/334 - 20s - loss: 0.0492 - accuracy: 0.9798 - precision: 0.9698 - recall: 0.9903 - f1score: 0.9795 - val_loss: 52.8349 - val_accuracy: 0.9741 - val_precision: 0.9707 - val_recall: 0.9808 - val_f1score: 0.9752\n",
    "Epoch 23/100\n",
    "334/334 - 20s - loss: 0.0481 - accuracy: 0.9800 - precision: 0.9722 - recall: 0.9891 - f1score: 0.9801 - val_loss: 60.3751 - val_accuracy: 0.9750 - val_precision: 0.9804 - val_recall: 0.9718 - val_f1score: 0.9755\n",
    "Epoch 24/100\n",
    "\n",
    "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
    "334/334 - 19s - loss: 0.0491 - accuracy: 0.9798 - precision: 0.9722 - recall: 0.9891 - f1score: 0.9801 - val_loss: 58.3349 - val_accuracy: 0.9729 - val_precision: 0.9651 - val_recall: 0.9838 - val_f1score: 0.9738\n",
    "Epoch 25/100\n",
    "334/334 - 20s - loss: 0.0469 - accuracy: 0.9807 - precision: 0.9733 - recall: 0.9901 - f1score: 0.9812 - val_loss: 47.7934 - val_accuracy: 0.9755 - val_precision: 0.9708 - val_recall: 0.9828 - val_f1score: 0.9763\n",
    "Epoch 26/100\n",
    "334/334 - 19s - loss: 0.0454 - accuracy: 0.9816 - precision: 0.9734 - recall: 0.9912 - f1score: 0.9819 - val_loss: 44.9249 - val_accuracy: 0.9748 - val_precision: 0.9729 - val_recall: 0.9793 - val_f1score: 0.9756\n",
    "Epoch 27/100\n",
    "334/334 - 19s - loss: 0.0456 - accuracy: 0.9810 - precision: 0.9738 - recall: 0.9897 - f1score: 0.9813 - val_loss: 45.3040 - val_accuracy: 0.9748 - val_precision: 0.9730 - val_recall: 0.9792 - val_f1score: 0.9756\n",
    "Epoch 28/100\n",
    "334/334 - 20s - loss: 0.0451 - accuracy: 0.9817 - precision: 0.9753 - recall: 0.9898 - f1score: 0.9821 - val_loss: 43.1199 - val_accuracy: 0.9765 - val_precision: 0.9752 - val_recall: 0.9801 - val_f1score: 0.9772\n",
    "Epoch 29/100\n",
    "334/334 - 19s - loss: 0.0443 - accuracy: 0.9817 - precision: 0.9750 - recall: 0.9898 - f1score: 0.9819 - val_loss: 35.2175 - val_accuracy: 0.9760 - val_precision: 0.9734 - val_recall: 0.9811 - val_f1score: 0.9768\n",
    "Epoch 30/100\n",
    "334/334 - 19s - loss: 0.0437 - accuracy: 0.9823 - precision: 0.9744 - recall: 0.9915 - f1score: 0.9825 - val_loss: 43.1690 - val_accuracy: 0.9757 - val_precision: 0.9798 - val_recall: 0.9741 - val_f1score: 0.9764\n",
    "Epoch 31/100\n",
    "334/334 - 19s - loss: 0.0442 - accuracy: 0.9820 - precision: 0.9749 - recall: 0.9900 - f1score: 0.9819 - val_loss: 26.8468 - val_accuracy: 0.9762 - val_precision: 0.9758 - val_recall: 0.9792 - val_f1score: 0.9770\n",
    "Epoch 00031: early stopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = compile_and_train(nasnet_model, num_epochs=EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = compile_and_train(inresnet_model, num_epochs=EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = compile_and_train(denseNet201_model, num_epochs=EPOCH)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Epoch 1/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = VGG_model(model_input)\n",
    "# nasnet_model = ResNet_model(model_input)\n",
    "denseNet201_model = DenseNet201_model(model_input)\n",
    "\n",
    "vgg_model.load_weights('/home/workspace/user-workspace/workspace/weights/VGG_model')#.hdf5\n",
    "# nasnet_model.load_weights('/home/workspace/user-workspace/workspace/weights/nasnet_model')\n",
    "denseNet201_model.load_weights('/home/workspace/user-workspace/workspace/weights/DenseNet201_model')\n",
    "\n",
    "models = [vgg_model, denseNet201_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ensemble(models, model_input):\n",
    "    \n",
    "#     outputs = [model.outputs[0] for model in models]\n",
    "#     y = Average()(outputs)\n",
    "    \n",
    "#     model = Model(model_input, y, name='ensemble2')\n",
    "#     model.compile(loss=\"binary_crossentropy\", optimizer=Adam(), metrics=['accuracy']) \n",
    "    \n",
    "#     return model\n",
    "# ensemble_model = ensemble(models, model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(models, model_input):\n",
    "    \n",
    "    outputs = [model.outputs[0] for model in models]\n",
    "    y = Average()(outputs)\n",
    "    \n",
    "    model = Model(model_input, y, name='ensemble2')\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(), metrics=['accuracy', precision, recall, f1score])  \n",
    "    \n",
    "    return model\n",
    "ensemble_model = ensemble(models, model_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### vgg 모델만 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = VGG_model(model_input)\n",
    "vgg_model.load_weights('/home/workspace/user-workspace/workspace/weights/VGG_model')#.hdf5ensemble_model = vgg_model = VGG_model(model_input)\n",
    "\n",
    "ensemble_model = vgg_model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
    "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
    "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
    "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
    "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
    "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('vgg_model')\n",
    "# evaluate_error(vgg_model)\n",
    "# print()\n",
    "# print()\n",
    "# print('denseNet201_model')\n",
    "# evaluate_error(denseNet201_model)\n",
    "# print()\n",
    "# print()\n",
    "# print('ensemble_model')\n",
    "# evaluate_error(ensemble_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at confusion matrix \n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = ensemble_model.predict(X_val)\n",
    "# Convert predictions classes to one hot vectors \n",
    "# Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "# Y_true = np.argmax(Y_val,axis = 1) \n",
    "# compute the confusion matrix\n",
    "\n",
    "Y_pred_class= tf.cast(Y_pred>0.5,dtype = tf.float32)\n",
    "confusion_mtx = confusion_matrix(Y_val, Y_pred_class) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = np.loadtxt(\"/home/workspace/data/.train/.task153/data/test/test.csv\",delimiter=\",\",dtype='str')\n",
    "test_df = pd.DataFrame(csv_data[1:], columns=['file_name', 'tile_name','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir = '/home/workspace/data/.train/.task153/data/test/'\n",
    "# file_list = os.listdir(path_dir)\n",
    "\n",
    "import csv\n",
    "\n",
    "def submit(model):\n",
    "    \n",
    "    \n",
    "    f = open('/home/workspace/user-workspace/prediction/prediction.csv', 'w', encoding='utf-8')\n",
    "    wr = csv.writer(f)\n",
    "    \n",
    "    for i in range(len(test_df)) :\n",
    "    # for i in range(100) :\n",
    "        #11.tif\t\n",
    "        \n",
    "        im = pilimg.open( path_dir + test_df['file_name'][i] )\n",
    "        # im = pilimg.open( '/home/workspace/data/.train/.task153/data/train/11.tif' )\n",
    "        # im = pilimg.open( '/home/workspace/data/.train/.task153/data/train/0.tif' )\n",
    "        \n",
    "        pitest=[]\n",
    "        pitest.append(np.array(im))\n",
    "        pitest=np.array(pitest)    \n",
    "        # Predict the values from the validation dataset\n",
    "        Y_pred = model.predict(pitest)\n",
    "        \n",
    "        # print(type(Y_pred)) # numpy.ndarray\n",
    "        \n",
    "        class_one = Y_pred > 0.5\n",
    "        if(class_one):\n",
    "            wr.writerow(['1'])\n",
    "        else:\n",
    "            wr.writerow(['0'])\n",
    "        \n",
    "    \n",
    "        if i%1000==0:\n",
    "            print(i)\n",
    "                         \n",
    "    f.close()        \n",
    "    \n",
    "submit(ensemble_model)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0\n",
    "1000\n",
    "2000\n",
    "3000\n",
    "4000\n",
    "5000\n",
    "6000\n",
    "7000\n",
    "8000\n",
    "9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit_data = np.loadtxt(\"/home/workspace/user-workspace/prediction/prediction.csv\",delimiter=\",\",dtype='str')\n",
    "# submit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pitest=np.array(pitest)\n",
    "# pitest=pitest/255\n",
    "# Y_pred = ensemble_model.predict(pitest)\n",
    "# Y_pred_class= tf.cast(Y_pred>0.5,dtype = tf.float32)\n",
    "# print(Y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipa.taskSubmit import nipa_submit\n",
    "import os\n",
    "\n",
    "team_id=\"1288\"\n",
    "task_no= \"153\"\n",
    "prediction_path = '/home/workspace/user-workspace/prediction/prediction.csv'\n",
    "# 파일 존재 여부 확인\n",
    "print(\"is file: \", os.path.isfile(prediction_path))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "is file:  True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 성공\n",
    "nipa_submit(team_id=team_id,\n",
    "task_no=task_no,\n",
    "result=prediction_path\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "20201110091351009271_7NRW.csv: 200"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
